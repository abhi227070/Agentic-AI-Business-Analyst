{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f869f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI ML\\AI ML Projects\\Gen AI projects\\Agentic-AI-Business-Analyst\\venv\\Lib\\site-packages\\langchain_nvidia_ai_endpoints\\_common.py:227: UserWarning: Found nvidia/nvidia-nemotron-nano-9b-v2 in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n",
      "d:\\AI ML\\AI ML Projects\\Gen AI projects\\Agentic-AI-Business-Analyst\\venv\\Lib\\site-packages\\langchain_nvidia_ai_endpoints\\chat_models.py:637: UserWarning: Model 'nvidia/nvidia-nemotron-nano-9b-v2' is not known to support tools. Your tool binding may fail at inference time.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatNVIDIA(model = \"nvidia/nvidia-nemotron-nano-9b-v2\")\n",
    "\n",
    "@tool\n",
    "def math_calculator(expression: str) -> float:\n",
    "    \"\"\"\n",
    "    A tool to evaluate mathematical expressions.\n",
    "\n",
    "    Args:\n",
    "        expression (str): A valid mathematical expression as a string.\n",
    "                          Example: \"5+10*2\" or \"(12/4)+3\".\n",
    "\n",
    "    Returns:\n",
    "        float: The computed result of the expression.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the expression is invalid or unsafe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a safe evaluation environment\n",
    "        allowed_names = {\n",
    "            k: v for k, v in vars(__import__(\"math\")).items() if not k.startswith(\"__\")\n",
    "        }\n",
    "        allowed_names[\"abs\"] = abs\n",
    "        allowed_names[\"round\"] = round\n",
    "\n",
    "        # Evaluate safely\n",
    "        result = eval(expression, {\"__builtins__\": {}}, allowed_names)\n",
    "        return float(result)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Invalid expression: {expression}. Error: {str(e)}\")\n",
    "    \n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a highly skilled Math Assistant that solves problems step-by-step. \n",
    "If the question involves calculations, use the 'math_calculator' tool. \n",
    "Be clear and precise in your final answer.\n",
    "\"\"\"\n",
    "\n",
    "# Math Agent\n",
    "math_agent = create_react_agent(\n",
    "    model = model,\n",
    "    tools= [math_calculator],\n",
    "    prompt= (prompt),\n",
    "    name= \"math_agent\"\n",
    ")\n",
    "\n",
    "# for step in math_agent.stream({\"messages\": \"Hello my name is Abhijit. Can you tell me what is the product of 302 and 3?\"}, stream_mode=\"values\"):\n",
    "#     step['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c60214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatNVIDIA(model = \"nvidia/nvidia-nemotron-nano-9b-v2\")\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool to look up recent, factual, or real-time information on the web.\n",
    "    Also you can use this tool to get current datetime, weather or other realtime information. \n",
    "    Always call this tool if the user asks for news, current events, statistics, \n",
    "    product details, or anything that requires searching online.\n",
    "    \n",
    "    Input: A search query string.\n",
    "    Output: A brief summary of the top relevant search results.\n",
    "    \"\"\"\n",
    "    return search.run(query)\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a powerful Web Search Assistant. You have access to a web search tool\n",
    "that can retrieve the latest, most accurate information.\n",
    "\n",
    "Your job:\n",
    "1. When a user asks a question, carefully analyze it.\n",
    "2. Use the search tool if necessary to gather recent and relevant data.\n",
    "3. Summarize findings clearly, concisely, and accurately.\n",
    "4. Always include context or sources if possible.\n",
    "5. Avoid unnecessary details unless explicitly asked.\n",
    "\n",
    "Follow this reasoning pattern:\n",
    "Thought -> Action -> Observation -> Final Answer\n",
    "\n",
    "TOOLS:\n",
    "You have access to the following tool:\n",
    "{tools}\n",
    "\n",
    "Use the following format exactly:\n",
    "Question: the input question\n",
    "Thought: reasoning about what to do next\n",
    "Action: the action to take (must be one of [{tool_names}])\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (repeat Thought/Action/Observation as needed)\n",
    "Final Answer: the concise, factual, helpful answer to the user.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Web Search Agent\n",
    "web_search_agent = create_react_agent(\n",
    "    model = model,\n",
    "    tools = [web_search],\n",
    "    prompt= prompt,\n",
    "    name=\"web_search_agent\"\n",
    ")\n",
    "\n",
    "user_input = \"Can you tell me what is today's date and time in India chennai zone?\"\n",
    "# for steps in web_search_agent.stream({'messages': user_input}, stream_mode=\"values\"):\n",
    "#     steps[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "db = SQLDatabase.from_uri(\"mysql+mysqlconnector://root:abhijeet123@localhost:3306/youtube\")\n",
    "\n",
    "model = ChatNVIDIA(model = \"nvidia/nvidia-nemotron-nano-9b-v2\")\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db = db, llm=model)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer. Unless the user\n",
    "specifies a specific number of examples they wish to obtain, always limit your\n",
    "query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "You MUST double check your query before executing it. If you get an error while\n",
    "executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you\n",
    "can query. Do NOT skip this step.\n",
    "\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sql_agent = create_react_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt=system_prompt,\n",
    "    name=\"sql_agent\"\n",
    ")\n",
    "\n",
    "# for step in sql_agent.stream({'messages': 'how many records are there in revenue column?'}, stream_mode=\"values\"):\n",
    "#     step['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from langchain.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "@tool\n",
    "def viz_tool(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute Python code safely to generate visualizations.\n",
    "    Allowed plots: bar chart, pie chart, line chart, histogram.\n",
    "    Return base64 encoded image if visualization is created.\n",
    "    \"\"\"\n",
    "    local_vars = {}\n",
    "    try:\n",
    "        # Execute user code inside a restricted environment\n",
    "        exec(code, {\"plt\": plt, \"sns\": sns}, local_vars)\n",
    "\n",
    "        # If user generated a plot, capture it\n",
    "        fig = plt.gcf()\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Encode as base64\n",
    "        img_b64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "        return f\"![chart](data:image/png;base64,{img_b64})\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "model = ChatNVIDIA(model = \"nvidia/nvidia-nemotron-nano-9b-v2\")\n",
    "\n",
    "# Create agent\n",
    "vizualization_agent = create_react_agent(\n",
    "    model,\n",
    "    tools=[viz_tool],\n",
    "    prompt=(\n",
    "        \"You are a data visualization assistant.\\n\"\n",
    "        \"You can create charts using matplotlib and seaborn ONLY.\\n\"\n",
    "        \"Allowed chart types: bar chart, pie chart, line chart, histogram.\\n\"\n",
    "        \"When asked for visualization, call the viz_tool with correct Python code.\\n\"\n",
    "        \"Do not use streamlit. Just use matplotlib/seaborn.\\n\"\n",
    "    ),\n",
    "    name=\"vizualization_agent\"\n",
    ")\n",
    "\n",
    "# for step in vizualization_agent.stream({'messages': \"Show me a bar chart of values [3,7,2] with labels A,B,C\"}, stream_mode=\"values\"):\n",
    "#     step['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3e042a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Abhijeet. Send one mail on behalf of me to rushithajujjuri@gmail.com for a simple tea coffe party on 22nd Sept 2025 at 5pm in Manyata Tech park bangalore\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: mail_agent\n",
      "Tool Calls:\n",
      "  send_gmail_message (pHEVXvgSE)\n",
      " Call ID: pHEVXvgSE\n",
      "  Args:\n",
      "    to: ['rushithajujjuri@gmail.com']\n",
      "    subject: Invitation to Tea & Coffee Party on 22nd Sept 2025\n",
      "    message: Dear rushithajujjuri,\n",
      "\n",
      "You are invited to a simple tea and coffee party on 22nd September 2025 at 5:00 PM at Manyata Tech Park, Bangalore.\n",
      "\n",
      "Best regards,\n",
      "Abhijeet\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: send_gmail_message\n",
      "\n",
      "Message sent. Message Id: 1991ff49679a1fa0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: mail_agent\n",
      "\n",
      "Your email has been successfully sent to rushithajujjuri@gmail.com with the subject **\"Invitation to Tea & Coffee Party on 22nd Sept 2025\"**. The message ID is **1991ff49679a1fa0**. \n",
      "\n",
      "Let me know if you need any further assistance! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_community.gmail.utils import (\n",
    "    build_resource_service,\n",
    "    get_gmail_credentials,\n",
    ")\n",
    "from langchain_google_community import GmailToolkit\n",
    "\n",
    "# Can review scopes here https://developers.google.com/gmail/api/auth/scopes\n",
    "# For instance, readonly scope is 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "credentials = get_gmail_credentials(\n",
    "    token_file=\"token.json\",\n",
    "    scopes=[\"https://mail.google.com/\"],\n",
    "    client_secrets_file=\"client_secret_1057926938137-fjsavjsoj3vs44uqjbke5p05mnknei80.apps.googleusercontent.com.json\",\n",
    ")\n",
    "api_resource = build_resource_service(credentials=credentials)\n",
    "toolkit = GmailToolkit()\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "mail_agent = create_react_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    prompt=(\n",
    "        \"You are an intelligent Email Assistant.\\n\"\n",
    "        \"The user will ask you to send an email.\\n\\n\"\n",
    "        \"RULES:\\n\"\n",
    "        \"- Always create subject + body in a professional format.\\n\"\n",
    "        \"- Always format the body with line breaks:\\n\"\n",
    "        \"  Dear <Name>,\\n\"\n",
    "        \"      <main content>\\n\\n\"\n",
    "        \"  Best regards,\\n\"\n",
    "        \"  <Sender Name>\\n\\n\"\n",
    "        \"- If the user says 'send', you MUST call send_email_tool. \"\n",
    "        \"Do not just write the email text. Only use plain text as body content.\\n\"\n",
    "        \"- If the user only wants a draft (they say 'draft' or 'write'), \"\n",
    "        \"then just return the email text and do NOT call the tool.\\n\"\n",
    "        \"- If missing details, ask for clarification before sending.\\n\"\n",
    "        \"- After sending, confirm success or failure.\\n\"\n",
    "    ),\n",
    "    name= \"mail_agent\"\n",
    ")\n",
    "\n",
    "for step in mail_agent.stream({'messages': \"My name is Abhijeet. Send one mail on behalf of me to rushithajujjuri@gmail.com for a simple tea coffe party on 22nd Sept 2025 at 5pm in Manyata Tech park bangalore\"}, stream_mode=\"values\"):\n",
    "    step['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from IPython.display import display, Image\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "supervisor_agent = create_supervisor(\n",
    "    model= model,\n",
    "    agents= [math_agent, web_search_agent, sql_agent, vizualization_agent, mail_agent],\n",
    "    prompt=(\n",
    "        \"\"\"\n",
    "        You are a supervisor managing three agents:\n",
    "        - a math agent: Assign math-related calculations or problem-solving tasks to this agent.\n",
    "        - a web search agent: Assign tasks that require finding up-to-date or external information from the web to this agent.\n",
    "        - a SQL agent: Assign tasks that require retrieving or manipulating data from the connected database to this agent. \n",
    "        This agent knows the database schema and can handle CRUD operations. \n",
    "        If a user requests information about non-existent tables, columns, or databases, \n",
    "        instruct the SQL agent to politely inform the user about it.\n",
    "\n",
    "        Assign work to one agent at a time, do not call agents in parallel.\n",
    "        Do not perform any tasks yourself; only delegate to the appropriate agent.\n",
    "        Always choose the most suitable agent based on the user query.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    add_handoff_back_messages=True,\n",
    "    output_mode=\"full_history\",\n",
    ").compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "\n",
    "def pretty_print_message(message, indent=False):\n",
    "    pretty_message = message.pretty_repr(html=True)\n",
    "    if not indent:\n",
    "        print(pretty_message)\n",
    "        return\n",
    "\n",
    "    indented = \"\\n\".join(\"\\t\" + c for c in pretty_message.split(\"\\n\"))\n",
    "    print(indented)\n",
    "\n",
    "\n",
    "def pretty_print_messages(update, last_message=False):\n",
    "    is_subgraph = False\n",
    "    if isinstance(update, tuple):\n",
    "        ns, update = update\n",
    "        # skip parent graph updates in the printouts\n",
    "        if len(ns) == 0:\n",
    "            return\n",
    "\n",
    "        graph_id = ns[-1].split(\":\")[0]\n",
    "        print(f\"Update from subgraph {graph_id}:\")\n",
    "        print(\"\\n\")\n",
    "        is_subgraph = True\n",
    "\n",
    "    for node_name, node_update in update.items():\n",
    "        update_label = f\"Update from node {node_name}:\"\n",
    "        if is_subgraph:\n",
    "            update_label = \"\\t\" + update_label\n",
    "\n",
    "        print(update_label)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        messages = convert_to_messages(node_update[\"messages\"])\n",
    "        if last_message:\n",
    "            messages = messages[-1:]\n",
    "\n",
    "        for m in messages:\n",
    "            pretty_print_message(m, indent=is_subgraph)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = '1'\n",
    "config = {'configurable': {'thread_id': thread_id}}\n",
    "\n",
    "for chunk in supervisor_agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Show me a bar chart of values [3,7,2] with labels A,B,C\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    pretty_print_messages(chunk, last_message=True)\n",
    "\n",
    "final_message_history = chunk[\"supervisor\"][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "thread_id = '1'\n",
    "config = {'configurable': {'thread_id': thread_id}}\n",
    "\n",
    "while True:\n",
    "    \n",
    "    user_input = input(\"Enter your message: \")\n",
    "    print(f\"User: {user_input}\")\n",
    "    \n",
    "    if user_input.lower() in ('bye', 'exit', 'quit'):\n",
    "        break\n",
    "    \n",
    "    response = supervisor_agent.invoke({'messages': [HumanMessage(content=user_input)]}, config=config)\n",
    "    \n",
    "    print(f\"AI: {response['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e22c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
